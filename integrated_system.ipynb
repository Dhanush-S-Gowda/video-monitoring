{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef917d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bhuva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Initializing Integrated Person Tracking System...\n",
      "============================================================\n",
      "Loading Object Tracker...\n",
      "Loading Face Recognition Module...\n",
      "Warning: Could not load model from c:\\Users\\bhuva\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3607a4b44cbefb7cfdbd90d82db7e2a7182b9de76.json: File format not supported: filepath=c:\\Users\\bhuva\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3607a4b44cbefb7cfdbd90d82db7e2a7182b9de76.json. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(c:\\Users\\bhuva\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3607a4b44cbefb7cfdbd90d82db7e2a7182b9de76.json, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).\n",
      "Loaded 5 labels: ['bb', 'bb1', 'bb2', 'dhanush', 'jaipreet']\n",
      "Initializing Database Manager...\n",
      "Database initialized at presence_log.db\n",
      "============================================================\n",
      "System initialized successfully!\n",
      "\n",
      "Camera opened successfully\n",
      "\n",
      "Starting main processing loop...\n",
      "Controls:\n",
      "  'q' - Quit\n",
      "  's' - Show statistics\n",
      "  'r' - Reset statistics\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lap>=0.5.12'] not found, attempting AutoUpdate...\n",
      "Collecting lap>=0.5.12\n",
      "  Downloading lap-0.5.12-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\bhuva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from lap>=0.5.12) (2.1.1)\n",
      "Downloading lap-0.5.12-cp313-cp313-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.2 MB/s  0:00:01:01\n",
      "Installing collected packages: lap\n",
      "Successfully installed lap-0.5.12\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  3.6s, installed 1 package: ['lap>=0.5.12']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "[TRACK] Track 1 -> Unknown person (method: unknown)\n",
      "[TRACK] Track 2 -> Unknown person (method: unknown)\n",
      "\n",
      "Finalizing active sessions...\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 309\u001b[39m, in \u001b[36mIntegratedSystem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Display\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPerson Tracking System\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;66;03m# Handle keypresses\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhuva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\utils\\patches.py:77\u001b[39m, in \u001b[36mimshow\u001b[39m\u001b[34m(winname, mat)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[33;03mDisplay an image in the specified window.\u001b[39;00m\n\u001b[32m     62\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m \u001b[33;03m    >>> imshow(\"Example Window\", img)  # Display the image\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[43m_imshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwinname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43municode_escape\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 386\u001b[39m\n\u001b[32m    382\u001b[39m     system.run()\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 382\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Create and run system\u001b[39;00m\n\u001b[32m    372\u001b[39m system = IntegratedSystem(\n\u001b[32m    373\u001b[39m     yolo_model_path=args.yolo_model,\n\u001b[32m    374\u001b[39m     face_model_path=args.face_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    379\u001b[39m     camera_index=args.camera\n\u001b[32m    380\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 325\u001b[39m, in \u001b[36mIntegratedSystem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    322\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 341\u001b[39m, in \u001b[36mIntegratedSystem.stop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cap:\n\u001b[32m    339\u001b[39m     \u001b[38;5;28mself\u001b[39m.cap.release()\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdestroyAllWindows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[38;5;66;03m# Print final statistics\u001b[39;00m\n\u001b[32m    344\u001b[39m \u001b[38;5;28mself\u001b[39m.print_statistics()\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Integrated System\n",
    "Combines object tracking, face recognition, and database logging.\n",
    "Main pipeline for person detection, identification, and logging.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from typing import Dict, Optional\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "from object_tracker import ObjectTracker\n",
    "from face_recognition_module import FaceRecognitionModule\n",
    "from database_manager import DatabaseManager\n",
    "\n",
    "\n",
    "class IntegratedSystem:\n",
    "    \"\"\"\n",
    "    Main system that integrates object tracking, face recognition, and logging.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 yolo_model_path: str = \"best.pt\",\n",
    "                 face_model_path: str = \"keras_model.h5\",\n",
    "                 labels_path: str = \"labels.txt\",\n",
    "                 db_path: str = \"presence_log.db\",\n",
    "                 reappear_threshold: int = 30,\n",
    "                 cleanup_interval: int = 60,\n",
    "                 camera_index: int = 0):\n",
    "        \"\"\"\n",
    "        Initialize the integrated system.\n",
    "        \n",
    "        Args:\n",
    "            yolo_model_path: Path to YOLO model\n",
    "            face_model_path: Path to face recognition model\n",
    "            labels_path: Path to labels file\n",
    "            db_path: Path to SQLite database\n",
    "            reappear_threshold: Threshold for re-appearance detection (seconds)\n",
    "            cleanup_interval: Interval for cleaning up inactive tracks (seconds)\n",
    "            camera_index: Camera device index\n",
    "        \"\"\"\n",
    "        print(\"Initializing Integrated Person Tracking System...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Initialize components\n",
    "        print(\"Loading Object Tracker...\")\n",
    "        self.tracker = ObjectTracker(model_path=yolo_model_path)\n",
    "        \n",
    "        print(\"Loading Face Recognition Module...\")\n",
    "        self.face_recognizer = FaceRecognitionModule(\n",
    "            model_path=face_model_path,\n",
    "            labels_path=labels_path\n",
    "        )\n",
    "        \n",
    "        print(\"Initializing Database Manager...\")\n",
    "        self.db = DatabaseManager(\n",
    "            db_path=db_path,\n",
    "            reappear_threshold=reappear_threshold\n",
    "        )\n",
    "        \n",
    "        # Camera\n",
    "        self.camera_index = camera_index\n",
    "        self.cap = None\n",
    "        \n",
    "        # Processing settings\n",
    "        self.cleanup_interval = cleanup_interval\n",
    "        self.last_cleanup = time.time()\n",
    "        \n",
    "        # Statistics\n",
    "        self.stats = {\n",
    "            'frames_processed': 0,\n",
    "            'detections': 0,\n",
    "            'faces_recognized': 0,\n",
    "            'body_matches': 0,\n",
    "            'unknown': 0\n",
    "        }\n",
    "        \n",
    "        # Threading\n",
    "        self.running = False\n",
    "        self.processing_queue = queue.Queue(maxsize=5)\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"System initialized successfully!\")\n",
    "        print()\n",
    "    \n",
    "    def start_camera(self) -> bool:\n",
    "        \"\"\"\n",
    "        Start the camera capture.\n",
    "        \n",
    "        Returns:\n",
    "            True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        self.cap = cv2.VideoCapture(self.camera_index)\n",
    "        \n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Cannot open camera at index {self.camera_index}\")\n",
    "            return False\n",
    "        \n",
    "        # Set camera properties for better performance\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        self.cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "        \n",
    "        print(f\"Camera opened successfully\")\n",
    "        return True\n",
    "    \n",
    "    def process_detections(self, detections: list):\n",
    "        \"\"\"\n",
    "        Process detections from object tracker through face recognition and logging.\n",
    "        \n",
    "        Args:\n",
    "            detections: List of detection dictionaries from ObjectTracker\n",
    "        \"\"\"\n",
    "        for det in detections:\n",
    "            track_id = det['track_id']\n",
    "            cropped_img = det['cropped_img']\n",
    "            class_name = det['class_name']\n",
    "            \n",
    "            # Only process person detections\n",
    "            if class_name.lower() != 'person':\n",
    "                continue\n",
    "            \n",
    "            self.stats['detections'] += 1\n",
    "            \n",
    "            # Run face recognition\n",
    "            recognition_result = self.face_recognizer.process_detection(\n",
    "                cropped_img, track_id\n",
    "            )\n",
    "            \n",
    "            identity = recognition_result.get('identity')\n",
    "            method = recognition_result.get('method')\n",
    "            \n",
    "            # Update statistics\n",
    "            if method == 'face':\n",
    "                self.stats['faces_recognized'] += 1\n",
    "            elif method == 'body':\n",
    "                self.stats['body_matches'] += 1\n",
    "            elif method == 'unknown':\n",
    "                self.stats['unknown'] += 1\n",
    "            \n",
    "            # Log to database if identity is known\n",
    "            if identity:\n",
    "                try:\n",
    "                    log_id = self.db.log_detection(identity, track_id)\n",
    "                    print(f\"[LOG] Track {track_id} -> {identity} (method: {method}, log_id: {log_id})\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error logging detection: {e}\")\n",
    "            else:\n",
    "                print(f\"[TRACK] Track {track_id} -> Unknown person (method: {method})\")\n",
    "    \n",
    "    def cleanup_inactive_tracks(self):\n",
    "        \"\"\"Periodically cleanup inactive tracks.\"\"\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if current_time - self.last_cleanup > self.cleanup_interval:\n",
    "            print(\"\\n[CLEANUP] Running cleanup of inactive tracks...\")\n",
    "            self.db.cleanup_inactive_tracks(timeout=self.cleanup_interval)\n",
    "            self.tracker.cleanup_stale_tracks(timeout=self.cleanup_interval)\n",
    "            self.last_cleanup = current_time\n",
    "    \n",
    "    def draw_ui(self, frame: np.ndarray, detections: list) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Draw UI elements on frame.\n",
    "        \n",
    "        Args:\n",
    "            frame: Original frame\n",
    "            detections: List of detections\n",
    "            \n",
    "        Returns:\n",
    "            Annotated frame\n",
    "        \"\"\"\n",
    "        # Start with annotated frame from tracker\n",
    "        annotated = self.tracker.get_annotated_frame(frame, detections)\n",
    "        \n",
    "        # Add system info overlay\n",
    "        overlay_height = 120\n",
    "        overlay = np.zeros((overlay_height, frame.shape[1], 3), dtype=np.uint8)\n",
    "        overlay[:] = (40, 40, 40)  # Dark gray background\n",
    "        \n",
    "        # Statistics text\n",
    "        y_offset = 25\n",
    "        line_height = 22\n",
    "        \n",
    "        stats_text = [\n",
    "            f\"Frames: {self.stats['frames_processed']}  |  Detections: {self.stats['detections']}\",\n",
    "            f\"Face Recognized: {self.stats['faces_recognized']}  |  Body Matched: {self.stats['body_matches']}  |  Unknown: {self.stats['unknown']}\",\n",
    "            f\"Active Tracks: {len(self.tracker.tracked_objects)}  |  Time: {datetime.now().strftime('%H:%M:%S')}\",\n",
    "        ]\n",
    "        \n",
    "        for i, text in enumerate(stats_text):\n",
    "            cv2.putText(overlay, text, (10, y_offset + i * line_height),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "        \n",
    "        # Add system name\n",
    "        cv2.putText(overlay, \"Person Tracking System\", (10, 100),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        cv2.putText(overlay, \"Press 'q' to quit | 's' for stats | 'r' to reset\",\n",
    "                   (frame.shape[1] - 450, 100),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "        \n",
    "        # Combine overlay with frame\n",
    "        result = np.vstack([overlay, annotated])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        \"\"\"Print detailed statistics.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SYSTEM STATISTICS\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Frames Processed:    {self.stats['frames_processed']}\")\n",
    "        print(f\"Total Detections:    {self.stats['detections']}\")\n",
    "        print(f\"Face Recognized:     {self.stats['faces_recognized']}\")\n",
    "        print(f\"Body Matched:        {self.stats['body_matches']}\")\n",
    "        print(f\"Unknown:             {self.stats['unknown']}\")\n",
    "        print(f\"Active Tracks:       {len(self.tracker.tracked_objects)}\")\n",
    "        print()\n",
    "        \n",
    "        # Show active sessions\n",
    "        active_sessions = self.db.get_active_sessions()\n",
    "        print(f\"Active Sessions ({len(active_sessions)}):\")\n",
    "        for session in active_sessions:\n",
    "            print(f\"  {session['user']:15} | Track: {session['track_id']:3} | \"\n",
    "                  f\"Start: {session['start_time']} | End: {session['end_time']}\")\n",
    "        \n",
    "        # Show today's completed sessions\n",
    "        today_sessions = self.db.get_sessions_by_date()\n",
    "        completed = [s for s in today_sessions if s['status'] == 'completed']\n",
    "        print(f\"\\nCompleted Sessions Today ({len(completed)}):\")\n",
    "        for session in completed:\n",
    "            duration_min = session['duration'] // 60 if session['duration'] else 0\n",
    "            duration_sec = session['duration'] % 60 if session['duration'] else 0\n",
    "            print(f\"  {session['user']:15} | {session['start_time']} - {session['end_time']} | \"\n",
    "                  f\"Duration: {duration_min}m {duration_sec}s\")\n",
    "        \n",
    "        print(\"=\" * 60 + \"\\n\")\n",
    "    \n",
    "    def reset_statistics(self):\n",
    "        \"\"\"Reset statistics counters.\"\"\"\n",
    "        self.stats = {\n",
    "            'frames_processed': 0,\n",
    "            'detections': 0,\n",
    "            'faces_recognized': 0,\n",
    "            'body_matches': 0,\n",
    "            'unknown': 0\n",
    "        }\n",
    "        print(\"\\n[RESET] Statistics reset\")\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Main processing loop.\n",
    "        \"\"\"\n",
    "        if not self.start_camera():\n",
    "            return\n",
    "        \n",
    "        print(\"\\nStarting main processing loop...\")\n",
    "        print(\"Controls:\")\n",
    "        print(\"  'q' - Quit\")\n",
    "        print(\"  's' - Show statistics\")\n",
    "        print(\"  'r' - Reset statistics\")\n",
    "        print()\n",
    "        \n",
    "        self.running = True\n",
    "        fps_counter = 0\n",
    "        fps_start_time = time.time()\n",
    "        current_fps = 0\n",
    "        \n",
    "        try:\n",
    "            while self.running:\n",
    "                # Read frame\n",
    "                success, frame = self.cap.read()\n",
    "                \n",
    "                if not success:\n",
    "                    print(\"Failed to read frame, retrying...\")\n",
    "                    time.sleep(0.1)\n",
    "                    continue\n",
    "                \n",
    "                self.stats['frames_processed'] += 1\n",
    "                fps_counter += 1\n",
    "                \n",
    "                # Calculate FPS every second\n",
    "                if time.time() - fps_start_time > 1.0:\n",
    "                    current_fps = fps_counter / (time.time() - fps_start_time)\n",
    "                    fps_counter = 0\n",
    "                    fps_start_time = time.time()\n",
    "                \n",
    "                # Track objects\n",
    "                detections = self.tracker.process_frame(frame)\n",
    "                \n",
    "                # Process detections (face recognition + logging)\n",
    "                if detections:\n",
    "                    self.process_detections(detections)\n",
    "                \n",
    "                # Periodic cleanup\n",
    "                self.cleanup_inactive_tracks()\n",
    "                \n",
    "                # Draw UI\n",
    "                display_frame = self.draw_ui(frame, detections)\n",
    "                \n",
    "                # Add FPS\n",
    "                cv2.putText(display_frame, f\"FPS: {current_fps:.1f}\", (10, display_frame.shape[0] - 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "                \n",
    "                # Display\n",
    "                cv2.imshow(\"Person Tracking System\", display_frame)\n",
    "                \n",
    "                # Handle keypresses\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    print(\"\\nShutting down...\")\n",
    "                    break\n",
    "                elif key == ord('s'):\n",
    "                    self.print_statistics()\n",
    "                elif key == ord('r'):\n",
    "                    self.reset_statistics()\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nInterrupted by user\")\n",
    "        \n",
    "        finally:\n",
    "            self.stop()\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        self.running = False\n",
    "        \n",
    "        # Finalize all active sessions\n",
    "        print(\"\\nFinalizing active sessions...\")\n",
    "        active_sessions = self.db.get_active_sessions()\n",
    "        for session in active_sessions:\n",
    "            self.db.finalize_entry(session['id'])\n",
    "        \n",
    "        # Release camera\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # Print final statistics\n",
    "        self.print_statistics()\n",
    "        \n",
    "        print(\"System stopped successfully\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Entry point for the integrated system.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Integrated Person Tracking System\")\n",
    "    parser.add_argument(\"--yolo-model\", type=str, default=\"best.pt\",\n",
    "                       help=\"Path to YOLO model\")\n",
    "    parser.add_argument(\"--face-model\", type=str, default=\"keras_model.h5\",\n",
    "                       help=\"Path to face recognition model\")\n",
    "    parser.add_argument(\"--labels\", type=str, default=\"labels.txt\",\n",
    "                       help=\"Path to labels file\")\n",
    "    parser.add_argument(\"--db\", type=str, default=\"presence_log.db\",\n",
    "                       help=\"Path to database file\")\n",
    "    parser.add_argument(\"--threshold\", type=int, default=30,\n",
    "                       help=\"Re-appearance threshold in seconds\")\n",
    "    parser.add_argument(\"--camera\", type=int, default=0,\n",
    "                       help=\"Camera device index\")\n",
    "    parser.add_argument(\"--cleanup-interval\", type=int, default=60,\n",
    "                       help=\"Cleanup interval in seconds\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Create and run system\n",
    "    system = IntegratedSystem(\n",
    "        yolo_model_path=args.yolo_model,\n",
    "        face_model_path=args.face_model,\n",
    "        labels_path=args.labels,\n",
    "        db_path=args.db,\n",
    "        reappear_threshold=args.threshold,\n",
    "        cleanup_interval=args.cleanup_interval,\n",
    "        camera_index=args.camera\n",
    "    )\n",
    "    \n",
    "    system.run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-gpu)",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
